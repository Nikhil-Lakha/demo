{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...\n",
       "1          1  It's not like we lack evidence of anthropogeni...\n",
       "2          2  RT @RawStory: Researchers say we have three ye...\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('Train.csv', usecols=['message', 'sentiment'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting number of messages in each sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data, removing links and @Mentions and Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"RT \",\" \")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say we have three years to act o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker  wired   2016 was a pivotal year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>it's 2016, and a racist, sexist, climate cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message\n",
       "0          1  polyscimajor epa chief doesn't think carbon di...\n",
       "1          1  it's not like we lack evidence of anthropogeni...\n",
       "2          2    researchers say we have three years to act o...\n",
       "3          1   todayinmaker  wired   2016 was a pivotal year...\n",
       "4          1    it's 2016, and a racist, sexist, climate cha..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_df = standardize_text(train_df, 'message')\n",
    "clean_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(post):\n",
    "    return ''.join([l for l in post if l not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say we have three years to act o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker  wired   2016 was a pivotal year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>its 2016 and a racist sexist climate change ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...\n",
       "1          1  its not like we lack evidence of anthropogenic...\n",
       "2          2    researchers say we have three years to act o...\n",
       "3          1   todayinmaker  wired   2016 was a pivotal year...\n",
       "4          1    its 2016 and a racist sexist climate change ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_df['message'] = clean_train_df['message'].apply(remove_punctuation)\n",
    "clean_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "exclude_words = set((\"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", \n",
    "                     'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", \n",
    "                     'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan',\n",
    "                     \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \n",
    "                     'won', \"won't\", 'wouldn', \"wouldn't\", 'not', \"aren't\", \"don't\"))\n",
    "\n",
    "new_stopwords = stopwords - exclude_words\n",
    "\n",
    "messages = clean_train_df['message'].to_numpy()\n",
    "\n",
    "def remove_stopwords(messages):\n",
    "    output_array=[]\n",
    "    for sentence in messages:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word.lower() not in new_stopwords:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>not like lack evidence anthropogenic global wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say three years act climate change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 racist sexist climate change denying bigo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>worth read whether dont believe climate change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>mike pence doesn believe global warming smokin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>six big things today fight climate change clim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8yo nephew inconsolable wants die old age like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>offense like not believe global warming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...\n",
       "1          1  not like lack evidence anthropogenic global wa...\n",
       "2          2  researchers say three years act climate change...\n",
       "3          1  todayinmaker wired 2016 pivotal year war clima...\n",
       "4          1  2016 racist sexist climate change denying bigo...\n",
       "5          1     worth read whether dont believe climate change\n",
       "6          1  mike pence doesn believe global warming smokin...\n",
       "7          1  six big things today fight climate change clim...\n",
       "8          1  8yo nephew inconsolable wants die old age like...\n",
       "9          1            offense like not believe global warming"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_df['message'] = remove_stopwords(messages)\n",
    "clean_train_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer, word_tokenize\n",
    "\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "clean_train_df['tokens'] = clean_train_df['message'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>not like lack evidence anthropogenic global wa...</td>\n",
       "      <td>[not, like, lack, evidence, anthropogenic, glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say three years act climate change...</td>\n",
       "      <td>[researchers, say, three, years, act, climate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "      <td>[todayinmaker, wired, 2016, pivotal, year, war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 racist sexist climate change denying bigo...</td>\n",
       "      <td>[2016, racist, sexist, climate, change, denyin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1          1  not like lack evidence anthropogenic global wa...   \n",
       "2          2  researchers say three years act climate change...   \n",
       "3          1  todayinmaker wired 2016 pivotal year war clima...   \n",
       "4          1  2016 racist sexist climate change denying bigo...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [not, like, lack, evidence, anthropogenic, glo...  \n",
       "2  [researchers, say, three, years, act, climate,...  \n",
       "3  [todayinmaker, wired, 2016, pivotal, year, war...  \n",
       "4  [2016, racist, sexist, climate, change, denyin...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>not like lack evidence anthropogenic global wa...</td>\n",
       "      <td>[not, like, lack, evidence, anthropogenic, glo...</td>\n",
       "      <td>[not, like, lack, evid, anthropogen, global, w...</td>\n",
       "      <td>not like lack evidence anthropogenic global wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say three years act climate change...</td>\n",
       "      <td>[researchers, say, three, years, act, climate,...</td>\n",
       "      <td>[research, say, three, year, act, climat, chan...</td>\n",
       "      <td>researcher say three year act climate change late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "      <td>[todayinmaker, wired, 2016, pivotal, year, war...</td>\n",
       "      <td>[todayinmak, wire, 2016, pivot, year, war, cli...</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 racist sexist climate change denying bigo...</td>\n",
       "      <td>[2016, racist, sexist, climate, change, denyin...</td>\n",
       "      <td>[2016, racist, sexist, climat, chang, deni, bi...</td>\n",
       "      <td>2016 racist sexist climate change denying bigo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1          1  not like lack evidence anthropogenic global wa...   \n",
       "2          2  researchers say three years act climate change...   \n",
       "3          1  todayinmaker wired 2016 pivotal year war clima...   \n",
       "4          1  2016 racist sexist climate change denying bigo...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [not, like, lack, evidence, anthropogenic, glo...   \n",
       "2  [researchers, say, three, years, act, climate,...   \n",
       "3  [todayinmaker, wired, 2016, pivotal, year, war...   \n",
       "4  [2016, racist, sexist, climate, change, denyin...   \n",
       "\n",
       "                                                stem  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [not, like, lack, evid, anthropogen, global, w...   \n",
       "2  [research, say, three, year, act, climat, chan...   \n",
       "3  [todayinmak, wire, 2016, pivot, year, war, cli...   \n",
       "4  [2016, racist, sexist, climat, chang, deni, bi...   \n",
       "\n",
       "                                               lemma  \n",
       "0  polyscimajor epa chief doesnt think carbon dio...  \n",
       "1  not like lack evidence anthropogenic global wa...  \n",
       "2  researcher say three year act climate change late  \n",
       "3  todayinmaker wired 2016 pivotal year war clima...  \n",
       "4  2016 racist sexist climate change denying bigo...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def dataset_stem(words, stemmer):\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "clean_train_df['stem'] = clean_train_df['tokens'].apply(dataset_stem, args=(stemmer,))\n",
    "clean_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>not like lack evidence anthropogenic global wa...</td>\n",
       "      <td>[not, like, lack, evidence, anthropogenic, glo...</td>\n",
       "      <td>[not, like, lack, evid, anthropogen, global, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say three years act climate change...</td>\n",
       "      <td>[researchers, say, three, years, act, climate,...</td>\n",
       "      <td>[research, say, three, year, act, climat, chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "      <td>[todayinmaker, wired, 2016, pivotal, year, war...</td>\n",
       "      <td>[todayinmak, wire, 2016, pivot, year, war, cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 racist sexist climate change denying bigo...</td>\n",
       "      <td>[2016, racist, sexist, climate, change, denyin...</td>\n",
       "      <td>[2016, racist, sexist, climat, chang, deni, bi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1          1  not like lack evidence anthropogenic global wa...   \n",
       "2          2  researchers say three years act climate change...   \n",
       "3          1  todayinmaker wired 2016 pivotal year war clima...   \n",
       "4          1  2016 racist sexist climate change denying bigo...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [not, like, lack, evidence, anthropogenic, glo...   \n",
       "2  [researchers, say, three, years, act, climate,...   \n",
       "3  [todayinmaker, wired, 2016, pivotal, year, war...   \n",
       "4  [2016, racist, sexist, climate, change, denyin...   \n",
       "\n",
       "                                                stem  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [not, like, lack, evid, anthropogen, global, w...  \n",
       "2  [research, say, three, year, act, climat, chan...  \n",
       "3  [todayinmak, wire, 2016, pivot, year, war, cli...  \n",
       "4  [2016, racist, sexist, climat, chang, deni, bi...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>not like lack evidence anthropogenic global wa...</td>\n",
       "      <td>[not, like, lack, evidence, anthropogenic, glo...</td>\n",
       "      <td>[not, like, lack, evid, anthropogen, global, w...</td>\n",
       "      <td>[not, like, lack, evidence, anthropogenic, glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say three years act climate change...</td>\n",
       "      <td>[researchers, say, three, years, act, climate,...</td>\n",
       "      <td>[research, say, three, year, act, climat, chan...</td>\n",
       "      <td>[researcher, say, three, year, act, climate, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "      <td>[todayinmaker, wired, 2016, pivotal, year, war...</td>\n",
       "      <td>[todayinmak, wire, 2016, pivot, year, war, cli...</td>\n",
       "      <td>[todayinmaker, wired, 2016, pivotal, year, war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 racist sexist climate change denying bigo...</td>\n",
       "      <td>[2016, racist, sexist, climate, change, denyin...</td>\n",
       "      <td>[2016, racist, sexist, climat, chang, deni, bi...</td>\n",
       "      <td>[2016, racist, sexist, climate, change, denyin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1          1  not like lack evidence anthropogenic global wa...   \n",
       "2          2  researchers say three years act climate change...   \n",
       "3          1  todayinmaker wired 2016 pivotal year war clima...   \n",
       "4          1  2016 racist sexist climate change denying bigo...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [not, like, lack, evidence, anthropogenic, glo...   \n",
       "2  [researchers, say, three, years, act, climate,...   \n",
       "3  [todayinmaker, wired, 2016, pivotal, year, war...   \n",
       "4  [2016, racist, sexist, climate, change, denyin...   \n",
       "\n",
       "                                                stem  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [not, like, lack, evid, anthropogen, global, w...   \n",
       "2  [research, say, three, year, act, climat, chan...   \n",
       "3  [todayinmak, wire, 2016, pivot, year, war, cli...   \n",
       "4  [2016, racist, sexist, climat, chang, deni, bi...   \n",
       "\n",
       "                                               lemma  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [not, like, lack, evidence, anthropogenic, glo...  \n",
       "2  [researcher, say, three, year, act, climate, c...  \n",
       "3  [todayinmaker, wired, 2016, pivotal, year, war...  \n",
       "4  [2016, racist, sexist, climate, change, denyin...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def dataset_lemma(words, lemmatizer):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]   \n",
    "\n",
    "clean_train_df['lemma'] = clean_train_df['tokens'].apply(dataset_lemma, args=(lemmatizer, ))\n",
    "clean_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>not like lack evidence anthropogenic global wa...</td>\n",
       "      <td>[not, like, lack, evidence, anthropogenic, glo...</td>\n",
       "      <td>not like lack evid anthropogen global warm</td>\n",
       "      <td>not like lack evidence anthropogenic global wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say three years act climate change...</td>\n",
       "      <td>[researchers, say, three, years, act, climate,...</td>\n",
       "      <td>research say three year act climat chang late</td>\n",
       "      <td>researcher say three year act climate change late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "      <td>[todayinmaker, wired, 2016, pivotal, year, war...</td>\n",
       "      <td>todayinmak wire 2016 pivot year war climat chang</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 racist sexist climate change denying bigo...</td>\n",
       "      <td>[2016, racist, sexist, climate, change, denyin...</td>\n",
       "      <td>2016 racist sexist climat chang deni bigot lea...</td>\n",
       "      <td>2016 racist sexist climate change denying bigo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1          1  not like lack evidence anthropogenic global wa...   \n",
       "2          2  researchers say three years act climate change...   \n",
       "3          1  todayinmaker wired 2016 pivotal year war clima...   \n",
       "4          1  2016 racist sexist climate change denying bigo...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [not, like, lack, evidence, anthropogenic, glo...   \n",
       "2  [researchers, say, three, years, act, climate,...   \n",
       "3  [todayinmaker, wired, 2016, pivotal, year, war...   \n",
       "4  [2016, racist, sexist, climate, change, denyin...   \n",
       "\n",
       "                                                stem  \\\n",
       "0  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1         not like lack evid anthropogen global warm   \n",
       "2      research say three year act climat chang late   \n",
       "3   todayinmak wire 2016 pivot year war climat chang   \n",
       "4  2016 racist sexist climat chang deni bigot lea...   \n",
       "\n",
       "                                               lemma  \n",
       "0  polyscimajor epa chief doesnt think carbon dio...  \n",
       "1  not like lack evidence anthropogenic global wa...  \n",
       "2  researcher say three year act climate change late  \n",
       "3  todayinmaker wired 2016 pivotal year war clima...  \n",
       "4  2016 racist sexist climate change denying bigo...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_sentence = []\n",
    "for words in clean_train_df['lemma']:\n",
    "    lemma_sentence.append(' '.join(words))\n",
    "\n",
    "stem_sentence = []\n",
    "for words in clean_train_df['stem']:\n",
    "    stem_sentence.append(' '.join(words))\n",
    "    \n",
    "clean_train_df['lemma'] = lemma_sentence\n",
    "clean_train_df['stem'] = stem_sentence\n",
    "\n",
    "clean_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2)\n",
    "    \n",
    "X = vectorizer.fit_transform(clean_train_df['lemma']).toarray()\n",
    "y = clean_train_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "def model_selection(model, X_train, X_val, y_train, y_val):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return print(f1_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5814861303004495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NL3005\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_selection(LogisticRegression(),X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5417303670231479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_selection(KNeighborsClassifier(),X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_selection(SVC(kernel='linear'),X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54643951931924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_selection(DecisionTreeClassifier(),X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5816196761349723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "model_selection(RandomForestClassifier(n_estimators=60),X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6087586339601438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "model_selection(MultinomialNB(),X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SVC(kernel='linear')\n",
    "sc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "tweet_ids = test_df['tweetid']\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe will now be looking to china to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nputin got to you too jill ! \\ntrump does...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'female orgasms cause global warming!'\\n sar...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  europe will now be looking to china to make su...   169760\n",
       "1  combine this with the polling of staffers re c...    35326\n",
       "2  the scary, unimpeachable evidence that climate...   224985\n",
       "3      \\nputin got to you too jill ! \\ntrump does...   476263\n",
       "4    'female orgasms cause global warming!'\\n sar...   872928"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_df = standardize_text(test_df, 'message')\n",
    "clean_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe will now be looking to china to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the scary unimpeachable evidence that climate ...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nputin got to you too jill  \\ntrump doesn...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female orgasms cause global warming\\n sarcas...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  europe will now be looking to china to make su...   169760\n",
       "1  combine this with the polling of staffers re c...    35326\n",
       "2  the scary unimpeachable evidence that climate ...   224985\n",
       "3      \\nputin got to you too jill  \\ntrump doesn...   476263\n",
       "4    female orgasms cause global warming\\n sarcas...   872928"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_df['message'] = clean_test_df['message'].apply(remove_punctuation)\n",
    "clean_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe looking china make sure not alone fight...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine polling staffers climate change womens...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scary unimpeachable evidence climate change al...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin got jill trump doesnt believe climate ch...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female orgasms cause global warming sarcastic ...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trump muzzles employees several gov agencies e...</td>\n",
       "      <td>75639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes wrote 3rd yr comp sci ethics part told cli...</td>\n",
       "      <td>211536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>indonesian farmers weather climate change w co...</td>\n",
       "      <td>569434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>british scientists face huge hit us cuts clima...</td>\n",
       "      <td>315368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aid agriculture sustainable agriculture climat...</td>\n",
       "      <td>591733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  europe looking china make sure not alone fight...   169760\n",
       "1  combine polling staffers climate change womens...    35326\n",
       "2  scary unimpeachable evidence climate change al...   224985\n",
       "3  putin got jill trump doesnt believe climate ch...   476263\n",
       "4  female orgasms cause global warming sarcastic ...   872928\n",
       "5  trump muzzles employees several gov agencies e...    75639\n",
       "6  yes wrote 3rd yr comp sci ethics part told cli...   211536\n",
       "7  indonesian farmers weather climate change w co...   569434\n",
       "8  british scientists face huge hit us cuts clima...   315368\n",
       "9  aid agriculture sustainable agriculture climat...   591733"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_df['message'] = remove_stopwords(clean_test_df['message'])\n",
    "clean_test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe looking china make sure not alone fight...</td>\n",
       "      <td>169760</td>\n",
       "      <td>[europe, looking, china, make, sure, not, alon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine polling staffers climate change womens...</td>\n",
       "      <td>35326</td>\n",
       "      <td>[combine, polling, staffers, climate, change, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scary unimpeachable evidence climate change al...</td>\n",
       "      <td>224985</td>\n",
       "      <td>[scary, unimpeachable, evidence, climate, chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin got jill trump doesnt believe climate ch...</td>\n",
       "      <td>476263</td>\n",
       "      <td>[putin, got, jill, trump, doesnt, believe, cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female orgasms cause global warming sarcastic ...</td>\n",
       "      <td>872928</td>\n",
       "      <td>[female, orgasms, cause, global, warming, sarc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>brb writing poem climate change climatechange ...</td>\n",
       "      <td>895714</td>\n",
       "      <td>[brb, writing, poem, climate, change, climatec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>2016 year climate change came home hottest yea...</td>\n",
       "      <td>875167</td>\n",
       "      <td>[2016, year, climate, change, came, home, hott...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>pacific countries positive fiji leading global...</td>\n",
       "      <td>78329</td>\n",
       "      <td>[pacific, countries, positive, fiji, leading, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>hot must cause global warming aldublaboroflove</td>\n",
       "      <td>867455</td>\n",
       "      <td>[hot, must, cause, global, warming, aldublabor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>climate change global issue thats getting wors...</td>\n",
       "      <td>470892</td>\n",
       "      <td>[climate, change, global, issue, thats, gettin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10546 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  tweetid  \\\n",
       "0      europe looking china make sure not alone fight...   169760   \n",
       "1      combine polling staffers climate change womens...    35326   \n",
       "2      scary unimpeachable evidence climate change al...   224985   \n",
       "3      putin got jill trump doesnt believe climate ch...   476263   \n",
       "4      female orgasms cause global warming sarcastic ...   872928   \n",
       "...                                                  ...      ...   \n",
       "10541  brb writing poem climate change climatechange ...   895714   \n",
       "10542  2016 year climate change came home hottest yea...   875167   \n",
       "10543  pacific countries positive fiji leading global...    78329   \n",
       "10544     hot must cause global warming aldublaboroflove   867455   \n",
       "10545  climate change global issue thats getting wors...   470892   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [europe, looking, china, make, sure, not, alon...  \n",
       "1      [combine, polling, staffers, climate, change, ...  \n",
       "2      [scary, unimpeachable, evidence, climate, chan...  \n",
       "3      [putin, got, jill, trump, doesnt, believe, cli...  \n",
       "4      [female, orgasms, cause, global, warming, sarc...  \n",
       "...                                                  ...  \n",
       "10541  [brb, writing, poem, climate, change, climatec...  \n",
       "10542  [2016, year, climate, change, came, home, hott...  \n",
       "10543  [pacific, countries, positive, fiji, leading, ...  \n",
       "10544  [hot, must, cause, global, warming, aldublabor...  \n",
       "10545  [climate, change, global, issue, thats, gettin...  \n",
       "\n",
       "[10546 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_df['tokens'] = clean_test_df['message'].apply(tokeniser.tokenize)\n",
    "clean_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe looking china make sure not alone fight...</td>\n",
       "      <td>169760</td>\n",
       "      <td>[europe, looking, china, make, sure, not, alon...</td>\n",
       "      <td>[europ, look, china, make, sure, not, alon, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine polling staffers climate change womens...</td>\n",
       "      <td>35326</td>\n",
       "      <td>[combine, polling, staffers, climate, change, ...</td>\n",
       "      <td>[combin, poll, staffer, climat, chang, women, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scary unimpeachable evidence climate change al...</td>\n",
       "      <td>224985</td>\n",
       "      <td>[scary, unimpeachable, evidence, climate, chan...</td>\n",
       "      <td>[scari, unimpeach, evid, climat, chang, alread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin got jill trump doesnt believe climate ch...</td>\n",
       "      <td>476263</td>\n",
       "      <td>[putin, got, jill, trump, doesnt, believe, cli...</td>\n",
       "      <td>[putin, got, jill, trump, doesnt, believ, clim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female orgasms cause global warming sarcastic ...</td>\n",
       "      <td>872928</td>\n",
       "      <td>[female, orgasms, cause, global, warming, sarc...</td>\n",
       "      <td>[femal, orgasm, caus, global, warm, sarcast, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid  \\\n",
       "0  europe looking china make sure not alone fight...   169760   \n",
       "1  combine polling staffers climate change womens...    35326   \n",
       "2  scary unimpeachable evidence climate change al...   224985   \n",
       "3  putin got jill trump doesnt believe climate ch...   476263   \n",
       "4  female orgasms cause global warming sarcastic ...   872928   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [europe, looking, china, make, sure, not, alon...   \n",
       "1  [combine, polling, staffers, climate, change, ...   \n",
       "2  [scary, unimpeachable, evidence, climate, chan...   \n",
       "3  [putin, got, jill, trump, doesnt, believe, cli...   \n",
       "4  [female, orgasms, cause, global, warming, sarc...   \n",
       "\n",
       "                                                stem  \n",
       "0  [europ, look, china, make, sure, not, alon, fi...  \n",
       "1  [combin, poll, staffer, climat, chang, women, ...  \n",
       "2  [scari, unimpeach, evid, climat, chang, alread...  \n",
       "3  [putin, got, jill, trump, doesnt, believ, clim...  \n",
       "4  [femal, orgasm, caus, global, warm, sarcast, r...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_df['stem'] = clean_test_df['tokens'].apply(dataset_stem, args=(stemmer,))\n",
    "clean_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe looking china make sure not alone fight...</td>\n",
       "      <td>169760</td>\n",
       "      <td>[europe, looking, china, make, sure, not, alon...</td>\n",
       "      <td>[europ, look, china, make, sure, not, alon, fi...</td>\n",
       "      <td>[europe, looking, china, make, sure, not, alon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine polling staffers climate change womens...</td>\n",
       "      <td>35326</td>\n",
       "      <td>[combine, polling, staffers, climate, change, ...</td>\n",
       "      <td>[combin, poll, staffer, climat, chang, women, ...</td>\n",
       "      <td>[combine, polling, staffer, climate, change, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scary unimpeachable evidence climate change al...</td>\n",
       "      <td>224985</td>\n",
       "      <td>[scary, unimpeachable, evidence, climate, chan...</td>\n",
       "      <td>[scari, unimpeach, evid, climat, chang, alread...</td>\n",
       "      <td>[scary, unimpeachable, evidence, climate, chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin got jill trump doesnt believe climate ch...</td>\n",
       "      <td>476263</td>\n",
       "      <td>[putin, got, jill, trump, doesnt, believe, cli...</td>\n",
       "      <td>[putin, got, jill, trump, doesnt, believ, clim...</td>\n",
       "      <td>[putin, got, jill, trump, doesnt, believe, cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female orgasms cause global warming sarcastic ...</td>\n",
       "      <td>872928</td>\n",
       "      <td>[female, orgasms, cause, global, warming, sarc...</td>\n",
       "      <td>[femal, orgasm, caus, global, warm, sarcast, r...</td>\n",
       "      <td>[female, orgasm, cause, global, warming, sarca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid  \\\n",
       "0  europe looking china make sure not alone fight...   169760   \n",
       "1  combine polling staffers climate change womens...    35326   \n",
       "2  scary unimpeachable evidence climate change al...   224985   \n",
       "3  putin got jill trump doesnt believe climate ch...   476263   \n",
       "4  female orgasms cause global warming sarcastic ...   872928   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [europe, looking, china, make, sure, not, alon...   \n",
       "1  [combine, polling, staffers, climate, change, ...   \n",
       "2  [scary, unimpeachable, evidence, climate, chan...   \n",
       "3  [putin, got, jill, trump, doesnt, believe, cli...   \n",
       "4  [female, orgasms, cause, global, warming, sarc...   \n",
       "\n",
       "                                                stem  \\\n",
       "0  [europ, look, china, make, sure, not, alon, fi...   \n",
       "1  [combin, poll, staffer, climat, chang, women, ...   \n",
       "2  [scari, unimpeach, evid, climat, chang, alread...   \n",
       "3  [putin, got, jill, trump, doesnt, believ, clim...   \n",
       "4  [femal, orgasm, caus, global, warm, sarcast, r...   \n",
       "\n",
       "                                               lemma  \n",
       "0  [europe, looking, china, make, sure, not, alon...  \n",
       "1  [combine, polling, staffer, climate, change, w...  \n",
       "2  [scary, unimpeachable, evidence, climate, chan...  \n",
       "3  [putin, got, jill, trump, doesnt, believe, cli...  \n",
       "4  [female, orgasm, cause, global, warming, sarca...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_df['lemma'] = clean_test_df['tokens'].apply(dataset_lemma, args=(lemmatizer, ))\n",
    "clean_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = []\n",
    "cv = CountVectorizer(max_features=5000)\n",
    "for words in clean_test_df['lemma']:\n",
    "    test_messages.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(test_messages).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame({'tweetid': tweet_ids, 'sentiment': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('final_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    4982\n",
       " 1    2727\n",
       " 2    1515\n",
       "-1    1322\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.sentiment.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
